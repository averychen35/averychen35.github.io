<!DOCTYPE html>
<html>

<head>
    <title>Project 4</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <h1>Project 5: Fun With Diffusion Models!</h1>

    <h2>Part 0: Setup</h2>
    <div class="desc">
        I play around with some different prompts and embeddings, try out 20 vs 100 num inference steps, and use a random seed of 53.
        Is a happy berkeley student an oxymoron? :P 20 steps is the first row and 100 is the second
        The Berkeley student with greater inference steps has more high frequency details like the bricks on the ground. Only the oasis with more inference steps has water, and the color of the water is somewhat realistic. The witch with more inference steps also has more details in the hair and background.
    </div>
    <div class="image-row">
        <div class="image-container">
            <img src="0/berkeley_student_20.png">
            <div class="image-row">a happy berkeley student</div>
        </div>
        <div class="image-container">
            <img src="0/oasis_20.png">
             <div class="image-row">a photo of an oasis</div>
        </div>
        <div class="image-container">
            <img src="0/witch_20.png">
             <div class="image-row">an oil painting of a witch</div>
        </div>

    </div>
    <div class="image-row">
        <div class="image-container">
            <img src="0/berkeley_student_100.png">
        </div>
        <div class="image-container">
            <img src="0/oasis_100.png">
        </div>
        <div class="image-container">
            <img src="0/witch_100.png">
        </div>

    </div>

    <h2>Part 1: Sampling Loops</h2>
    <h3>1.1 Implementing the Forward Process</h3>
    I use torch.randn_like(image) to add noise distributed to a standard normal distribution that is the same shape as the image, and index into alphas_cumprod accordingly to get the alpha values at timestep t. 
    By running forward(im, t), I am able to produce a noisy version of the image at timestep t, where greater values of t result in a more noisy image.

    <div class="image-row">
        <div class="image-container">
            <img src="1.1/1.1_code.png">
            <div class="desc">code</div>
        </div>
    </div>
    <div class="image-row">
        <div class="image-container">
            <img src="1.7.2/campanile.png">
            <div class="desc">original</div>
        </div>
        <div class="image-container">
            <img src="1.1/1.1_250.png">
            <div class="desc">noise level 250</div>
        </div>
        <div class="image-container">
            <img src="1.1/1.1_500.png">
            <div class="desc">noise level 500</div>
        </div>
        <div class="image-container">
            <img src="1.1/1.1_750.png">
            <div class="desc">noise level 750</div>
        </div>

    </div>

        <h3>1.2 Classical Denoising</h3>
        I try denoising using classical methods: with torchvision.transforms.functional.gaussian_blur to remove the higher frequency components. I use kernel_size of 10 and the default calculated sigma. This is pretty ineffective as shown below. This is why we’re moving beyond classical methods into diffusion models!

    <div class="image-row">
        <div class="image-container">
            <img src="1.1/1.1_250.png">
            <div class="desc">noise level 250</div>
        </div>
        <div class="image-container">
            <img src="1.1/1.1_500.png">
            <div class="desc">noise level 500</div>
        </div>
        <div class="image-container">
            <img src="1.1/1.1_750.png">
            <div class="desc">noise level 750</div>
        </div>

    </div>

        <div class="image-row">
        <div class="image-container">
            <img src="1.2/1.2_250.png">
            <div class="desc">Gaussian blurred noise level 250</div>
        </div>
        <div class="image-container">
            <img src="1.2/1.2_500.png">
            <div class="desc">Gaussian blurred noise level 500</div>
        </div>
        <div class="image-container">
            <img src="1.2/1.2_750.png">
            <div class="desc">Gaussian blurred noise level 750</div>
        </div>

    </div>

            <h3>1.3 One-Step Denoising</h3>
            The idea behind diffusion models is the following: it’s easy to add noise to an image, so our model aims to “reverse” this process by denoising the image. 
        The idea behind one-step denoising is estimating the noise within an image using a pretrained diffusion model and removing it to obtain a less noisy image. We use the text embedding of “a high quality photo”. After estimating the noise, I rearrange the equation to solve for the clean image, which requires subtracting the scaled noise and dividing the result by the sqrt of alpha. 

    <div class="image-row">
        <div class="image-container">
            <img src="1.1/1.1_250.png">
            <div class="desc">noise level 250</div>
        </div>
        <div class="image-container">
            <img src="1.1/1.1_500.png">
            <div class="desc">noise level 500</div>
        </div>
        <div class="image-container">
            <img src="1.1/1.1_750.png">
            <div class="desc">noise level 750</div>
        </div>

    </div>

        <div class="image-row">
        <div class="image-container">
            <img src="1.3/1.3_250.png">
            <div class="desc">one step denoised noise level 250</div>
        </div>
        <div class="image-container">
            <img src="1.3/1.3_500.png">
            <div class="desc">one step denoised level 500</div>
        </div>
        <div class="image-container">
            <img src="1.3/1.3_750.png">
            <div class="desc">one step denoised level 750</div>
        </div>

    </div>

                <h3>1.4 Iterative Denoising</h3>
        Later, using strided timesteps that are too large causes issues. But we don’t worry about that here! The idea behind strided timesteps is to save time by computing multiple steps at once. I use the strided_timesteps denoted in this problem with stride of 30. The iteratively denoised campanile seems much more clear, but also more deviated from the original. The one steps is more blurry, and the Gaussian blurred campanile still has a lot of colorful noise. 
    <div class="image-row">
        <div class="image-container">
            <img src="1.4/1.4_code.png">
            <div class="desc">code</div>
        </div>
    </div>
    <div class="image-row">
        <div class="image-container">
            <img src="1.4/1.4_90.png">
            <div class="desc">t=90</div>
        </div>
        <div class="image-container">
            <img src="1.4/1.4_240.png">
            <div class="desc">t=240</div>
        </div>
        <div class="image-container">
            <img src="1.4/1.4_390.png">
            <div class="desc">t=390</div>
        </div>
        <div class="image-container">
            <img src="1.4/1.4_540.png">
            <div class="desc">t=540</div>
        </div>
        <div class="image-container">
            <img src="1.4/1.4_690.png">
            <div class="desc">t=690</div>
        </div>

    </div>
        <div class="image-row">
            <div class="image-container">
            <img src="1.7.2/campanile.png">
            <div class="desc">original</div>
        </div>
        <div class="image-container">
            <img src="1.4/1.4_final.png">
            <div class="desc">final iteratively denoised</div>
        </div>
        <div class="image-container">
            <img src="1.4/1.4_one_step.png">
            <div class="desc">one step denoised</div>
        </div>
        <div class="image-container">
            <img src="1.4/1.4_gaussian.png">
            <div class="desc">gaussian blurred</div>
        </div>
        </div>
    <h3>1.5 Diffusion Model Sampling</h3>
        To generate random photos, I use the prompt “a high quality photo” and generate random noise in the shape of the image torch.randn. Then, I use my iterative_denoise function to generate the following images. At the beginning, a lot of people were being generated, which freaked me out so I generated more images.

    <div class="image-row">
        <div class="image-container">
            <img src="1.5/1.5_1.png">
            <div class="desc">sample 1</div>
        </div>
        <div class="image-container">
            <img src="1.5/1.5_2.png">
            <div class="desc">sample 2</div>
        </div>
        <div class="image-container">
            <img src="1.5/1.5_3.png">
            <div class="desc">sample 3</div>
        </div>
        <div class="image-container">
            <img src="1.5/1.5_4.png">
            <div class="desc">sample 4</div>
        </div>
        <div class="image-container">
            <img src="1.5/1.5_5.png">
            <div class="desc">sample 5</div>
        </div>

    </div>

        <h3>1.6 Classifier-Free Guidance (CFG)</h3>
        To get more high quality images, we generate an unconditional noise estimate in addition to a conditional noise estimate, calling UNet twice, and use a combination of these two to generate a noise estimate. You can tell that the images in this section are more high quality than the previous, and overall much more vibrant!
    <div class="image-row">
        <div class="image-container">
            <img src="1.6/1.6_code.png">
            <div class="desc">code</div>
        </div>
    </div>
        <div class="image-row">
        <div class="image-container">
            <img src="1.6/1.6_1.png">
            <div class="desc">sample 1</div>
        </div>
        <div class="image-container">
            <img src="1.6/1.6_2.png">
            <div class="desc">sample 2</div>
        </div>
        <div class="image-container">
            <img src="1.6/1.6_3.png">
            <div class="desc">sample 3</div>
        </div>
        <div class="image-container">
            <img src="1.6/1.6_4.png">
            <div class="desc">sample 4</div>
        </div>
        <div class="image-container">
            <img src="1.6/1.6_5.png">
            <div class="desc">sample 5</div>
        </div>

    </div>

            <h3>1.7 Image-to-image Translation</h3>
        
        I run iterative_denoise_cfg with different noise levels, [1, 3, 5, 7, 10, 20]. As the noise level increases, we go from the “high quality photo” closer and closer to the campanile. It is interesting to see how the general shape and background look good in the beginning, but the details get closer to the original image as we add more noise. 

    <div class="image-row">
        <div class="image-container">
            <img src="1.7.2/campanile.png">
            <div class="desc">original image</div>
        </div>
        <div class="image-container">
            <img src="1.7/1.7_1.png">
            <div class="desc">noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7/1.7_3.png">
            <div class="desc">noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7/1.7_5.png">
            <div class="desc">noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7/1.7_7.png">
            <div class="desc">noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7/1.7_10.png">
            <div class="desc">noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7/1.7_20.png">
            <div class="desc">noise 20</div>
        </div>
        </div>
    <div class="image-row">
        <div class="image-container">
            <img src="1.7/sunset.jpg">
            <div class="desc">original image</div>
        </div>
        <div class="image-container">
            <img src="1.7/sunset_1.png">
            <div class="desc">noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7/sunset_3.png">
            <div class="desc">noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7/sunset_5.png">
            <div class="desc">noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7/sunset_7.png">
            <div class="desc">noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7/sunset_10.png">
            <div class="desc">noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7/sunset_20.png">
            <div class="desc">noise 20</div>
        </div>
        </div>
    
            <div class="image-row">
        <div class="image-container">
            <img src="1.7/pumpkin.png">
            <div class="desc">original image</div>
        </div>
        <div class="image-container">
            <img src="1.7/pumpkin_1.png">
            <div class="desc">noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7/pumpkin_3.png">
            <div class="desc">noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7/pumpkin_5.png">
            <div class="desc">noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7/pumpkin_7.png">
            <div class="desc">noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7/pumpkin_10.png">
            <div class="desc">noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7/pumpkin_20.png">
            <div class="desc">noise 20</div>
        </div>
        </div>
    
    <h3>1.7.1 Editing Hand-Drawn and Web Images</h3>
        
        I now try using images from online or hand drawn images. It looks like the model may have included some nudity for the drawing of the guy with the spiky hair so I redacted one of the images :/ It’s interesting to see how we go from people to more mushroom shaped to my mushroom. For the dino, the evolution seems to be mostly in the colors, and it’s funny how we go from realistic people to a penguin. 

    <div class="image-row">
        <div class="image-container">
            <img src="1.7.1/1.7.1_hand_drawn_1.png">
            <div class="desc">spiky hair man</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_1.png">
            <div class="desc">noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_1.png">
            <div class="desc">noise 3 (redacted)</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_5.png">
            <div class="desc">noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_7.png">
            <div class="desc">noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_10.png">
            <div class="desc">noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_20.png">
            <div class="desc">noise 20</div>
        </div>
    </div>
    
    <div class="image-row">
        <div class="image-container">
            <img src="1.7.1/1.7.1_mushroom.png">
            <div class="desc">mushroom</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_1_m.png">
            <div class="desc">noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_m_3.png">
            <div class="desc">noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_m_5.png">
            <div class="desc">noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_m_7.png">
            <div class="desc">noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_m_10.png">
            <div class="desc">noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/1.7.1_m_20.png">
            <div class="desc">noise 20</div>
        </div>
        
        </div>
    <div class="image-row">
        <div class="image-container">
            <img src="1.7.1/dino.png">
            <div class="desc">dino</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/dino_1.png">
            <div class="desc">noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/dino_3.png">
            <div class="desc">noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/dino_5.png">
            <div class="desc">noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/dino_7.png">
            <div class="desc">noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/dino_10.png">
            <div class="desc">noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/dino_20.png">
            <div class="desc">noise 20</div>
        </div>
        
        </div>
        <div class="image-row">
        <div class="image-container">
            <img src="1.7.1/penguin.jpg">
            <div class="desc">penguin</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/penguin_1.png">
            <div class="desc">noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/penguin_3.png">
            <div class="desc">noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/penguin_5.png">
            <div class="desc">noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/penguin_7.png">
            <div class="desc">noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/penguin_10.png">
            <div class="desc">noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7.1/penguin_20.png">
            <div class="desc">noise 20</div>
        </div>
        
        </div>
    
        <h3>1.7.2 Inpainting</h3>
        
        For inpainting, I make minor edits to the iterative_denoise_cfg function. I add extra code to compute the noised original at this timestep and another line to utilize the mask when constructing the new image. I tried the pumpkin image twice and it filled it in with a pumpkin twice! I have to alter the step size within strided timestpes to be 10 to achieve better results!
<div class="image-row">
        <div class="image-container">
            <img src="1.7.2/1.7.2_code.png">
            <div class="desc">code</div>
        </div>
    </div>
        <div class="image-row">
        <div class="image-container">
            <img src="1.7.2/campanile.png">
            <div class="desc">og campanile</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/camp_mask.png">
            <div class="desc">mask</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/camp_replace.png">
            <div class="desc">to replace</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/1.7.2.png">
            <div class="desc">final image</div>
        </div>
    </div>

    <div class="image-row">
        <div class="image-container">
            <img src="1.7/pumpkin.png">
            <div class="desc">og pumpkin</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/pumpkin_mask.png">
            <div class="desc">mask</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/pumpkin_replace.png">
            <div class="desc">to replace</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/pumpkin_inpaint.png">
            <div class="desc">final image</div>
        </div>
    </div>
    <div class="image-row">
        <div class="image-container">
            <img src="1.7/sunset.jpg">
            <div class="desc">original image</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/mask1.png">
            <div class="desc">mask</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/replace1.png">
            <div class="desc">to replace</div>
        </div>
        <div class="image-container">
            <img src="1.7.2/new_sunset.png">
            <div class="desc">final image</div>
        </div>
    </div>

<h3>1.7.3 Text-Conditional Image-to-image Translation</h3>
        
       For this step, I use a text prompt to guide a given image to also look like a text prompt. I call iterative_denoise_cfg with a different value for the noise and the greater the noise, the closer the image is to the original image. 
       Prompts I used: "a christmas themed dog", "a photo of an oasis", "an oil painting of a princess". 
       It is interesting to observe how the positioning and coloring of the dog is more like a pumpkin, and how the background of the oasis resembles the oasis more. The princess and campanile interpretation is quite interesting, I'm not sure why the arms are still out though!
            <div class="image-row">
        <div class="image-container">
            <img src="1.7/pumpkin.png">
            <div class="desc">og image: pumpkin</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/dog_1.png">
            <div class="desc">dog noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/dog_3.png">
            <div class="desc">dog noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/dog_5.png">
            <div class="desc">dog noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/dog_7.png">
            <div class="desc">dog noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/dog_10.png">
            <div class="desc">dog noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/dog_20.png">
            <div class="desc">dog noise 20</div>
        </div>
    </div>

    <div class="image-row">
        <div class="image-container">
            <img src="1.7/sunset.jpg">
            <div class="desc">og image: sunset</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/oasis_1.png">
            <div class="desc">oasis noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/oasis_3.png">
            <div class="desc">oasis noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/oasis_5.png">
            <div class="desc">oasis noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/oasis_7.png">
            <div class="desc">oasis noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/oasis_10.png">
            <div class="desc">oasis noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/oasis_20_yes.png">
            <div class="desc">oasis noise 20</div>
        </div>
    </div>

        <div class="image-row">
        <div class="image-container">
            <img src="1.7.2/campanile.png">
            <div class="desc">og image: campanile</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/princess_1.png">
            <div class="desc">princess noise 1</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/princess_3.png">
            <div class="desc">princess noise 3</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/princess_5.png">
            <div class="desc">princess noise 5</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/princess_7.png">
            <div class="desc">princess noise 7</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/princess_10.png">
            <div class="desc">princess noise 10</div>
        </div>
        <div class="image-container">
            <img src="1.7.3/princess_20.png">
            <div class="desc">princess noise 20</div>
        </div>
    </div>
    
    <h3>1.8 Visual Anagrams</h3>
        
       I create visual anagrams which look like two different prompts right side up or upside down by obtaining two noise estimates, each with different orientation and prompt. I then flip the second noise estimate which corresponds to the flipped image, and average these two noise estimates. Here’s my two results and prompts!
        <div class="image-row">
        <div class="image-container">
            <img src="1.8/1.8_code.png">
            <div class="desc">code</div>
        </div>
    </div>
       <div class="image-row">
            <div class="image-container">
            <img src="1.8/cats.png">
            <div class="desc">an oil painting of two cats</div>
        </div>
        <div class="image-container">
            <img src="1.8/chess_pieces.png">
            <div class="desc">an oil painting of two chess pieces</div>
        </div>
        </div>
        <div class="image-row">
            <div class="image-container">
            <img src="1.8/city.png">
            <div class="desc">an oil painting of an urban city</div>
        </div>
        <div class="image-container">
            <img src="1.8/witch.png">
            <div class="desc">an oil painting of a witch</div>
        </div>
        </div>
        <h3>1.9 Hybrid Images</h3>
        
       To create hybrid images, I use a similar approach to part 1.8. Except these two noise estimates are computed on the image right side up with different prompts. I then use torchvision.transforms.function.gaussian_blur to get the low frequency and high frequency components of the noise estimates (low by just calling gaussian_blur on the noise, and the high by subtracting the gaussian_blur value from the original noise estimate). Then, I add these two noise estimates together to get the final hybrid images!
        <div class="image-row">
        <div class="image-container">
            <img src="1.9/1.9_code.png">
            <div class="desc">code</div>
        </div>
    </div>
       <div class="image-row">
            <div class="image-container">
            <img src="1.9/cats_chess.png">
            <div class="desc">near: an oil painting of two chess pieces</div>
            <div class="desc">far: an oil painting of two cats</div>
        </div>
        <div class="image-container">
            <img src="1.9/witch_city_2.png">
            <div class="desc">near: an oil painting of an urban city</div>
            <div class="desc">far: an oil painting of a witch</div>
        </div>
        </div>

    <h2>Part B: Training a Diffusion Model</h2>

    <h3>Part 1: Training a Single-Step Denoising UNet</h3>
    <h3>1.1 Implementing the UNet</h3>
    Alright! In this part, I build a UNet based on the architecture shown below. I build standard operations, that are pieced together to create our final architecture. 
    <div class="image-row">
        <div class="image-container">
            <img src="part_b/atomic_ops_new.png">
        </div>
    </div>
    <div class="image-row">
        <div class="image-container">
            <img src="part_b/unconditional_arch.png">
        </div>
    </div>

    <h3>1.2 Using the UNet to Train a Denoiser</h3>
    Now that our model is built, we must train it! To train our model, we use MNIST digits. To learn how to load the images from MNIST I used this  <a href="https://www.youtube.com/watch?v=33ysE1Gt1G4">video</a>.
I created a function to add noise based on a noise level for images–results are visualized below. 
<div class="image-row">
    <div class="image-container">
        <img src="part_b/noisy_image_level_0.png">
        <div class="desc">level 0</div>
    </div>
    <div class="image-container">
        <img src="part_b/noisy_image_level_0.2.png">
        <div class="desc">level 0.2</div>
    </div>
    <div class="image-container">
        <img src="part_b/noisy_image_level_0.4.png">
        <div class="desc">level 0.4</div>
    </div>
    <div class="image-container">
        <img src="part_b/noisy_image_level_0.6.png">
        <div class="desc">level 0.6</div>
    </div>
    <div class="image-container">
        <img src="part_b/noisy_image_level_0.8.png">
        <div class="desc">level 0.8</div>
    </div>
    <div class="image-container">
        <img src="part_b/noisy_image_level_1.png">
        <div class="desc">level 1</div>
    </div>
</div>

<h3>1.2.1 Training</h3>

While training with noise level 0.5, I add noise to each image, then use the model to predict the clean image corresponding to the noisy image. To calculate loss we take L2 loss over the clean image and the predicted clean image. We can see that epoch 5 has much more clear digits than epoch 1 which makes sense, because more training has happened by then!
<div class="image-row">
    <div class="image-container">
        <img src="part_b/training.png">
        <div class="desc">loss curve</div>
    </div>
</div>

<div class="image-row">
    <div class="image-container">
        <img src="part_b/1.2.1_input_image_0.png">
        <div class="desc">input image</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.1_noisy_image_0_epoch1.png">
        <div class="desc">epoch 1</div>
    </div>

        <div class="image-container">
        <img src="part_b/1.2.1_noisy_image_0_epoch5.png">
        <div class="desc">epoch 5</div>
    </div>
</div>

<div class="image-row">
    <div class="image-container">
        <img src="part_b/1.2.1_input_image_1.png">
        <div class="desc">input image</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.1_noisy_image_1_epoch1.png">
        <div class="desc">epoch 1</div>
    </div>

        <div class="image-container">
        <img src="part_b/1.2.1_noisy_image_1_epoch5.png">
        <div class="desc">epoch 5</div>
    </div>
</div>

<div class="image-row">
    <div class="image-container">
        <img src="part_b/1.2.1_input_image_2.png">
        <div class="desc">input image</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.1_noisy_image_2_epoch1.png">
        <div class="desc">epoch 1</div>
    </div>

        <div class="image-container">
        <img src="part_b/1.2.1_noisy_image_2_epoch5.png">
        <div class="desc">epoch 5</div>
    </div>
</div>

<h3>1.2.2 Out-of-Distribution Testing</h3>

Here, we sample out-of-distribution noise levels after the model is trained. The results on the number 7 for these two examples seem mostly legible until noise levels 0.8 and 1, where the resulting image features artifacts in the 7. 

<div class="image-row">
    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_level_0.png">
        <div class="desc">level 0</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_level_0.2.png">
        <div class="desc">level 0.2</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_level_0.4.png">
        <div class="desc">level 0.4</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_level_0.6.png">
        <div class="desc">level 0.6</div>
    </div>
    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_level_0.8.png">
        <div class="desc">level 0.8</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_level_1.png">
        <div class="desc">level 1</div>
    </div>
    </div>
    denoised results

    <div class="image-row">
    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_0_epoch5.png">
        <div class="desc">level 0</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_0.2_epoch5.png">
        <div class="desc">level 0.2</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_0.4_epoch5.png">
        <div class="desc">level 0.4</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_0.6_epoch5.png">
        <div class="desc">level 0.6</div>
    </div>
    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_0.8_epoch5.png">
        <div class="desc">level 0.8</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.2_noisy_image_1_epoch5.png">
        <div class="desc">level 1</div>
    </div>
    </div>

<h3>1.2.3 Denoising Pure Noise</h3>

We do an interesting experiment here, training the model with input images of pure noise. Because we’re minimizing mean squared error, we’re finding the “centroid” of all of our training images, or our average digit. This is a process of generating the average image because we start from noise. We can see that our average digit has a lot of curves, perhaps from lots of numbers having curves within them. Our image at 5 epochs looks smoother and it seems like we converge on the average image by then!

    <div class="image-row">
    <div class="image-container">
        <img src="part_b/1.2.3_input_image_0.png">
        <div class="desc">input image</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.3_noisy_image_0_epoch1.png">
        <div class="desc">epoch 1</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.3_noisy_image_0_epoch5.png">
        <div class="desc">epoch 5</div>
    </div>
    </div>

        <div class="image-row">
    <div class="image-container">
        <img src="part_b/1.2.3_input_image_1.png">
        <div class="desc">input image</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.3_noisy_image_1_epoch1.png">
        <div class="desc">epoch 1</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.3_noisy_image_1_epoch5.png">
        <div class="desc">epoch 5</div>
    </div>
    </div>

        <div class="image-row">
    <div class="image-container">
        <img src="part_b/1.2.3_input_image_2.png">
        <div class="desc">input image</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.3_noisy_image_2_epoch1.png">
        <div class="desc">epoch 1</div>
    </div>

    <div class="image-container">
        <img src="part_b/1.2.3_noisy_image_2_epoch5.png">
        <div class="desc">epoch 5</div>
    </div>
    </div>

    <h3>Part 2: Training a Flow Matching Model</h3>

    <h3>2.1 Adding Time Conditioning to UNet</h3>
    Now, instead of predicting the noisy image from a clean image, we predict the flow, or the velocity from a noisy image to a clean image. We do this by adding time conditioning to UNet with FCBlocks. Here is a diagram showing the new time conditioned unet and the FCBlock that is used to accomplish this.

    <div class="image-row">
        <div class="image-container">
            <img src="part_b/fc_long.png">
        </div>
    </div>
    <div class="image-row">
        <div class="image-container">
            <img src="part_b/conditional_arch_fm.png">
        </div>
    </div>

    <h3>2.2 Training the UNet</h3>

    Now that we have our time conditioned UNet, we have to train it! We use the following algorithm for training, where we randomly choose a training image and timestep from 0 to 1, add noise to get a noised image, and train our model to predict the flow at a certain timestep. I use a batch size of 64, an exponential learning rate decay, training for 10 epochs. 

        <div class="image-row">
        <div class="image-container">
            <img src="part_b/2.3_train.png">
            <div class="desc">training curve</div>
        </div>
    </div>
    <div class="image-row">
        <div class="image-container">
            <img src="part_b/algo1_t_only_fm.png">
            <div class="desc">training algorithm</div>
        </div>
    </div>

    <h3>2.3 Sampling from the UNet</h3>

    Here, I implement sampling with the following algorithm. You can see that at epoch 1 many of the digits seem like scribbles or blobs, but by epoch 10, most of the digits are legible! At first, I didn’t realize that I had to move my models to the device, and it was taking 5 hours. Later, it only took 6 minutes to train my model :’)

            <div class="image-row">

    <div class="image-row">
        <div class="image-container">
            <img src="part_b/algo2_t_only_fm.png">
            <div class="desc">sampling algorithm</div>
        </div>
    </div>
<div class="image-row">
        <div class="image-container">
            <img src="part_b/2.3_epoch1_grid_4x10.png">
            <div class="desc">epoch 1</div>
        </div>
    </div>
</div>
<div class="image-row">

       <div class="image-container">
            <img src="part_b/2.3_epoch5_grid_4x10.png">
            <div class="desc">epoch 5</div>
        </div>
    </div>
</div>

<div class="image-row">

       <div class="image-container">
            <img src="part_b/2.3_epoch10_grid_4x10.png">
            <div class="desc">epoch 10</div>
        </div>
    </div>
</div>

<h3>2.4 Adding Class-Conditioning to UNet</h3>

Instead of only conditioning on time, we can also add class-conditioning (on the classes for digits 0-9) to our architecture! We do this by adding 2 more FCBlocks. We create a one-hot vector for our class conditioning, and set it to 0 if we don’t want it to condition on the class. We also only use the class conditioning vector 90% of the time (or dropout 10% of the time). The dimensions here were kind of annoying but I figured it out eventually!

<h3>2.5 Training the UNet</h3>

Now we train with class conditioning as well as time conditioning. This is very similar to the last part, except we set the class to the zero vector (dropout) with p_cond. 



    <div class="image-row">
        <div class="image-container">
            <img src="part_b/algo3_c_fm.png">
            <div class="desc">training algorithm</div>
        </div>
    </div>

    <div class="image-row">
        <div class="image-container">
            <img src="part_b/2.5_train.png">
            <div class="desc">training curve</div>
        </div>
    </div>


    <h3>2.6 Sampling from the UNet</h3>
    Now, we sample from our class conditioned UNet! This is also pretty similar to the previous section, except we use classifier-free guidance to get our estimate for the next x_t. Results at epoch 1 are guessable, and results at epoch 10 are much crisper. 
        <div class="image-row">
        <div class="image-container">
            <img src="part_b/algo4_c_fm.png">
            <div class="desc">sampling algorithm</div>
        </div>
    </div>
<div class="image-row">
        <div class="image-container">
            <img src="part_b/epoch1.png">
            <div class="desc">epoch 1</div>
        </div>
    </div>
</div>
<div class="image-row">

       <div class="image-container">
            <img src="part_b/epoch5.png">
            <div class="desc">epoch 5</div>
        </div>
    </div>
</div>

<div class="image-row">

       <div class="image-container">
            <img src="part_b/epoch10.png">
            <div class="desc">epoch 10</div>
        </div>
    </div>
</div>
    
    To get rid of the annoying learning rate scheduler, I first tried the average learning rate which came out to be 1e-4. The results were not quite as good, so I tried a larger learning rate (1e-3) which had results comparable to that of the scheduler. I didn’t want to do 1e-2 for fear it would be too large, as that is our starting learning rate. 
<div class="image-row">
        <div class="image-container">
            <img src="part_b/2.6_epoch1_grid_4x10.png">
            <div class="desc">epoch 1</div>
        </div>
    </div>
</div>
<div class="image-row">

       <div class="image-container">
            <img src="part_b/2.6_epoch5_grid_4x10.png">
            <div class="desc">epoch 5</div>
        </div>
    </div>
</div>

<div class="image-row">

       <div class="image-container">
            <img src="part_b/2.6_epoch10_grid_4x10.png">
            <div class="desc">epoch 10</div>
        </div>
    </div>
</div>

This project helped solidify my understanding of training and sampling models from scratch! I thought it was cool to get a more technical understanding and look under a hood, after a more intuition based understanding of diffusion models presented in lecture. 
</body>

</html>