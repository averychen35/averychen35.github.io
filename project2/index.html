<!DOCTYPE html>
<html>

<head>
    <title>Project 2</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <h1>Project 2: Fun with Filters and Frequencies!
</h1>

    <h2>Part 1: Fun with Filters</h2>
    <h3>Part 1.1: Convolutions From Scratch!</h3>
    To start off, I implement my own four and two loop implementation of the scipy.signal.convolve2d, with mode=’same’.
    <div class="image-row">
    <div class="image-container">
            <img src="images/1.1/four_loops.png">
            <div class="desc">3274 seconds</div>
            </div>
    <div class="image-container">
            <img src="images/1.1/two_loops_code.png">
            <div class="desc">1311 seconds</div>
        </div>
    </div>
    <div class="image-row">
    <div class="image-container">
            <img src="images/starting_images/og_selfie.jpg">
            <div class="desc">starting image</div>
        </div>
    <div class="image-container">
            <img src="images/1.1/selfie.jpg">
            <div class="desc">resulting blurred selfie</div>
        </div>
        </div>
I construct a box filter to do blurring on my image, and the results look qualitatively the same for the two types of loops and the built in functions.

Runtime: scipy.signal.convolve2d is much faster (4.34 seconds), than two for loops, which is also significantly faster than four for loops. Although the second two loops are much smaller, they still require a few operations which probably adds to the longer runtime. For the scipy implementation, I wonder if they are able to use certain optimizations (loop unrolling like we learned about in 61C) to achieve even further optimizations as compared to the two loop filter I implemented.

In terms of boundaries, the way I implemented the convolution matches that as of mode=”same” within scipy. When doing “same” mode, “The output is the same size as in1, centered with respect to the ‘full’ output.”. My code just doesn’t consider values outside of the range of the image (those values just contribute 0 to the total sum), but scipy calculates the full convolution so that the resulting image is larger than im1, then crops. Even though the handling of boundaries in calculation is different, I believe that the final image and boundaries should appear the same in my implementation (which seems to be the case, based on my observations).
    <div class="image-row">
    <div class="image-container">
            <img src="images/1.1/selfie_dx.jpg">
            <div class="desc">convolved with D_x</div>
        </div>
    <div class="image-container">
            <img src="images/1.1/selfie_dy.jpg">
            <div class="desc">convolved with D_y</div>
        </div>
        </div>
</div>
I then convolve my image with the finite difference operators D_x and D_y. The hanging lights are much more clear in the D_xas they hang vertically -> there are greater changes when moving horizontally from wall to light back to wall, as well as observing the textures in the map in the upper left. For the D_y image, details like the top of my arm and top of my head are more clear. 
    <h3>Part 1.2: Finite Difference Operator</h3>
    <div class="desc">
    For part 1.2, we aim to find all the edges in the cameraman image!
    First, I convolve the image with the finite difference operators, D_x and D_y.
</div>
<div class="image-row">
    <img src="images/1.2/diff_op.png" alt="diff_op">
</div>
<div class="image-row">
    <div class="image-container">
            <img src="images/1.2/cameraman.png">
            <div class="desc">original image</div>
            </div>
    <div class="image-container">
            <img src="images/1.2/cameraman_dx.png">
            <div class="desc">convolving with dx </div>
        </div>
        <div class="image-container">
            <img src="images/1.2/cameraman_dy.png">
            <div class="desc">convolving with dy</div>
        </div>
</div>
<div class="desc">
The D_x convolution shows a lot of detail with the vertical lines, like the supports of the camera, the columns in the building. The D_y convolution shows more horizontal details, like the top of the camerman’s head and the tops of buildings. 
</div>
<div class="desc">

Next, I compute the gradient magnitude image by taking the square root of the sum of the squared values in the dx and dy image. 
</div>
<div class="image-row">
    <div class="image-container">
            <img src="images/1.2/cameraman_grad_mag.png">
            <div class="desc">gradient magnitude</div>
            </div>
    <div class="image-container">
            <img src="images/1.2/cameraman_bin_0.1.png">
            <div class="desc">0.1 threshold </div>
        </div>
        <div class="image-container">
            <img src="images/1.2/best_cameraman_bin_0.2.png">
            <div class="desc">0.2 threshold</div>
        </div>
        <div class="image-container">
            <img src="images/1.2/cameraman_bin_0.3.png">
            <div class="desc">0.3 threshold</div>
        </div>
</div>
<div class="desc">


I then experimented with various thresholds to binarize the gradient magnitude image and get an edge image. I settled upon 0.2 as my threshold, trying values from 0.1 to 0.9, incrementing by 0.1 each time. I find that 0.2 strikes the best balance between being too noisy and capturing all of the most important details. For example, the 0.1 threshold image is too noisy and there are artifacts that don’t exist in the original image in the sky and ground. However, the 0.3 threshold is missing some of the important details in the cameraman (arm and hand) and buildings in the background.
</div>
<div>
<h3>Part 1.3: Derivative of Gaussian (DoG) Filter</h3>
<div class="desc">
    Now, we aim to get rid of some of the noise by using the Gaussian filter! My Gaussian filter of size 10 and sigma = 10/6
    is created by taking the outer product of cv2.getGaussianKernel with itself as suggested.
</div>
<div class="image-row">
    <div class="image-container">
            <img src="images/1.3/gaussian_dx_big.png">
            <div class="desc">Gaussian of D_x</div>
        </div>
<div class="image-container">
            <img src="images/1.3/cameraman_gaus_dx.png">
            <div class="desc">Gaussian, then D_x</div>
        </div>
        <div class="image-container">
            <img src="images/1.3/cameraman_gaus_dy.png">
            <div class="desc">Gaussian, then D_y</div>
        </div>
        <div class="image-container">
            <img src="images/1.3/gaussian_dy_big.png">
            <div class="desc">Gaussian of D_y</div>
        </div>
</div>

</div>

</div>
<div class="desc">
    By convolving the cameraman image with the Gaussian filter, we get a blurred version of the original image. We then convolve the blurred image with D_x and D_y respectively. The resulting image looks to be a lot smoother than the original! This makes sense because applying the Gaussian filter removes high-frequency components from the image, making it look “smoother”. 

</div>
<div class="image-row">
<div class="image-container">
            <img src="images/1.3/cameraman_grad_mag_gaus_one.png">
            <div class="desc">gradient magnitude of Gaussian, then D_x/D_y</div>
        </div>
        <div class="image-container">
            <img src="images/1.3/cameraman_grad_mag_gaus.png">
            <div class="desc">Gaussian of gradient magnitude</div>
        </div>
</div>
</div>
<div class="desc">Taking the gradient magnitude of the Gaussian blurred D_x and D_y is the same as taking the Gaussian of the gradient magnitude image! This is due to the “nice” properties of convolutions that we learned about in lecture, including associativity, it is possible to show that these result in the same image! Thus, the order of when the Gaussian is applied to the gradient magnitude does not alter the final image.</div>
<div class="image-row"><div class="image-container">
            <img src="images/1.3/cameraman_gaus_0.05.png">
            <div class="desc">0.05 threshold</div>
        </div>
<div class="image-container">
            <img src="images/1.3/cameraman_gaus_0.1.png">
            <div class="desc">0.1 threshold</div>
        </div>
        <div class="image-container">
            <img src="images/1.3/cameraman_gaus_0.2.png">
            <div class="desc">0.2 threshold</div>
        </div>
        <div class="image-container">
            <img src="images/1.3/cameraman_gaus_0.3.png">
            <div class="desc">0.3 threshold</div>
        </div>
</div>
</div>
<div class="desc">

    I find that using a threshold of 0.05 produces the best edge image--anything larger (0.1 or above) loses a significant amount of detail.
</div>


<h2>Part 2: Fun with Frequencies!</h2>
<h3>Part 2.1: Image "Sharpening"</h3>
To sharpen our image, or get more high frequencies in our final image, we subtract the blurred version of the image (created with a Gaussian filter) from the original. Then, we can add more high frequencies to our original image to sharpen it. However, we can combine this into a single convolution operation. To create the mask passed into this convolution, I pass in the Gaussian filter, unit impulse function, and sharpening factor. I construct the filter by doing [(1 + sharpening factor) × impulse function - sharpening factor × G]. This effectively gets the high frequencies and amplifies them, by multiplying them by 1 + sharpening factor. This argument sharpening factor is somewhat misleading, it’s technically the sharpening factor + 1 (if I pass in 1, it’s really sharpening by a factor of 2). I repeat this process on the red, blue, and green, then stack them back together.
<div class="image-row">
<div class="image-container">
            <img src="images/2.1/unsharp_mask_filter.jpg">
            <div class="desc">taken from lecture slides</div>
        </div>
</div>
<div class="image-row">
<div class="image-container">
            <img src="images/2.1/taj.jpg">
            <div class="desc">original</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/taj_high_freq.png">
            <div class="desc">high frequencies</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/taj_blurred.png">
            <div class="desc">blurred</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/taj_sharpened.png">
            <div class="desc">factor of 2</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/taj_sharp.png">
            <div class="desc">factor of 4</div>
        </div>
</div>

<div class="desc">
    The even sharper Taj seems to look unrealistic. The sharpening of the scaffolding and details on the arch are exaggerated, especially for the distance from which the viewer is at. Additionally, there seems to be a glow around the top of the building, which makes the image look more surreal and less realistic.
</div>
<div class="image-row">
<div class="image-container">
            <img src="images/starting_images/landscape.jpg">
            <div class="desc">original</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/landscape_high.png">
            <div class="desc">high frequencies</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/landscape_sharp.png">
            <div class="desc">final, with factor 2</div>
        </div>
</div>
<div class="image-row">
<div class="image-container">
            <img src="images/2.1/fetch.jpg">
            <div class="desc">original</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/fetch_high.png">
            <div class="desc">high frequencies</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/fetch_sharp.png">
            <div class="desc">final, with factor 2</div>
        </div>
</div>
<div class="image-row">
<div class="image-container">
            <img src="images/starting_images/clear_dog.jpeg">
            <div class="desc">original</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/clear_dog_high.png">
            <div class="desc">high frequencies</div>
        </div>
        <div class="image-container">
            <img src="images/2.1/clear_dog_sharp.png">
            <div class="desc">final, with factor 2</div>
        </div>
</div>
I experiment with blurring, then sharpening a clear image. Upon quick glance, the image looks alright. But, we lose the detail and the softness in Katie’s fur. Especially if you look above her nose, a lot of the hairs look coarser (they’re white), losing the definition and detail that gives it the soft look in the original image. We cannot reconstruct the details that were lost through the blurring process.


<h3>Part 2.2: Hybrid Images</h3>
<div class="desc">
    Onto some scary looking hybrid images!! The idea behind creating hybrid images is taking advantage of the different viewing distances of high frequency and low frequencies, so what an image looks like changes as you look closer/further.
    I utilized the given image alignment code, with the same parameters for kerel size and sigma as before for the Gaussian filter.
Derek? Or Cat?
<div class="image-row">
<div class="image-container">
            <img src="images/2.2/DerekPicture.jpg">
            <div class="desc">Derek</div>
        </div>
        <div class="image-container">
            <img src="images/2.2/nutmeg.jpg">
            <div class="desc">cat</div>
        </div>
        <div class="image-container">
            <img src="images/2.2/hybrid_derek_nutmeg.png">
            <div class="desc">what species is this? Sigma1 = 0.25, sigma2 = 0.9</div>
        </div>
</div>
Do you see me, or my dog Katie?
<div class="image-row">

<div class="image-container">
            <img src="images/2.2/blurred_cleardog.png">
            <div class="desc">blurry katie!</div>
        </div>
<div class="image-container">
            <img src="images/2.2/aligned_selfie.png">
            <div class="desc">katie!</div>
        </div>
        <div class="image-container">
            <img src="images/2.2/aligned_cleardog.png">
            <div class="desc">me</div>
        </div>
        <div class="image-container">
            <img src="images/2.2/highfreq_selfie.png">
            <div class="desc">me, in high frequency</div>
        </div>
        
        </div>
</div>
</div>
<div class="image-container">
            <img src="images/2.2/hybrid_avery_cleardog.png">
            <div class="desc">blended image: sigma1 = 0.25, sigma2 = 5</div>
        </div>
        Fourier analysis!
        <div class="image-row">

<div class="image-container">
            <img src="images/2.2/fourier_blurred_cleardog.png">
            <div class="desc">blurry katie!</div>
        </div>
<div class="image-container">
            <img src="images/2.2/fourier_cleardog.png">
            <div class="desc">katie!</div>
        </div>
        <div class="image-container">
            <img src="images/2.2/fourier_selfie.png">
            <div class="desc">me</div>
        </div>
        <div class="image-container">
            <img src="images/2.2/fourier_highfreq_selfie.png">
            <div class="desc">me, in high frequency</div>
        </div>
        
        </div>
</div>
</div>
Katie's image doesn't have too many strong horizontal and vertical lines. Her fur seems to go in many directions

<div class="image-container">
            <img src="images/2.2/fourier_hybrid_avery_cleardog.png">
            <div class="desc">blended image</div>
        </div>

Does anyone remember the song pen pineapple apple pen?
<div class="image-row">


<div class="image-container">
            <img src="images/starting_images/pineapple.jpeg">
            <div class="desc">pineapple</div>
        </div>
        <div class="image-container">
            <img src="images/starting_images/apple.jpg">
            <div class="desc">apple</div>
        </div>
        <div class="image-container">
            <img src="images/2.2/pine_apple.png">
            <div class="desc">sigma1=0.3, sigma2=0.5</div>
        </div>
        
        </div>



Smiskis!
<div class="image-row">
<div class="image-container">
            <img src="images/starting_images/yoga.jpeg">
            <div class="desc">zen</div>
        </div>
<div class="image-container">
            <img src="images/starting_images/looking.jpeg">
            <div class="desc">hi there</div>
        </div>
        <div class="image-container">
            <img src="images/2.2/better_smiskis.png">
            <div class="desc"> sigma1=0.3, sigma2=0.8</div>
        </div>
        
        </div>



<h3>Part 2.3: Gaussian and Laplacian Stacks</h3>
I work on creating Gaussian and Laplacian stacks in this part! For the Gaussian stack, I repeatedly apply the Gaussian filter to the image until it gets blurrier and blurrier. For the Laplacian stack, I subtract the images in the Gaussian stack from each other to get specific bands of frequencies. The last layer of the Laplacian stack contains the lowest frequencies and is just taken from the Gaussian stack.
<div class="image-row">
    
<div class="image-container">
            <img src="images/2.3/apple_gaussian_level_0.png">
            
        </div>
<div class="image-container">
            <img src="images/2.3/apple_gaussian_level_1.png">
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_gaussian_level_2.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_gaussian_level_3.png">
           
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_gaussian_level_4.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_gaussian_level_5.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_gaussian_level_6.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_gaussian_level_7.png">
            
        </div>
        
        </div>
        Apple Gaussian stack

        <div class="image-row">
<div class="image-container">
            <img src="images/2.3/apple_laplacian_level_0.png">
            
        </div>
<div class="image-container">
            <img src="images/2.3/apple_laplacian_level_1.png">
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_laplacian_level_2.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_laplacian_level_3.png">
           
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_laplacian_level_4.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_laplacian_level_5.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_laplacian_level_6.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/apple_laplacian_level_7.png">
            
        </div>
        
        </div>
        Apple Laplacian stack
        <div class="image-row">
    
<div class="image-container">
            <img src="images/2.3/orange_gaussian_level_0.png">
            
        </div>
<div class="image-container">
            <img src="images/2.3/orange_gaussian_level_1.png">
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_gaussian_level_2.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_gaussian_level_3.png">
           
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_gaussian_level_4.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_gaussian_level_5.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_gaussian_level_6.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_gaussian_level_7.png">
            
        </div>
        
        </div>
        Orange Gaussian stack

        <div class="image-row">
<div class="image-container">
            <img src="images/2.3/orange_laplacian_level_0.png">
            
        </div>
<div class="image-container">
            <img src="images/2.3/orange_laplacian_level_1.png">
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_laplacian_level_2.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_laplacian_level_3.png">
           
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_laplacian_level_4.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_laplacian_level_5.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_laplacian_level_6.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.3/orange_laplacian_level_7.png">
            
        </div>
        
        </div>
        Apple Laplacian stack
<h3>Part 2.4: Multiresolution Blending (a.k.a. the oraple!)</h3>
Onto image blending! To implement this image blending algorithm, I took inspiration from the given paper and lecture slides. I created a binary mask of half 1s on the entire left half and half 0s on the entire right half, and applied a Gaussian filter to this mask for each level, resulting in greater blend for low frequencies and less intense blend for higher frequencies. For each value in the left image, I multiply by the mask array, and for each value in the right image, I multiply by 1- the value in the mask array. Here are my results with the orapple!

<div class="image-row">
    <div class="image-container">
            <img src="images/2.4/orapple/masked_im1_level_0.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/orapple/masked_im2_level_0.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/orapple/blended_level_0.png">
            
        </div>

</div>
<div class="image-row">
    <div class="image-container">
            <img src="images/2.4/orapple/masked_im1_level_2.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/orapple/masked_im2_level_2.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/orapple/blended_level_2.png">
            
        </div>

</div>
<div class="image-row">
    <div class="image-container">
            <img src="images/2.4/orapple/masked_im1_level_4.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/orapple/masked_im2_level_4.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/orapple/blended_level_4.png">
            
        </div>

</div>
<div class="image-row">
    <div class="image-container">
            <img src="images/2.4/blended_first.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/blended_second.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/orapple/final_blended_image.png">
            
        </div>

</div>
I’ve always wondered what it’s like to swim in a bowl of cereal. This didn’t blend perfectly because the kiddie pool tube is a lot thicker than the cereal bowl, but I tried my best. For this one, I used the given image alignment code, then the same horizontal mask as the previous orapple example.
<div class="image-row">
    <div class="image-container">
            <img src="images/starting_images/kiddie_pool.jpg">
            
        </div>
        <div class="image-container">
            <img src="images/starting_images/cereal_bowl.jpg">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/cereal_pool/final_blended_image.png">
            
        </div>
        Lastly, I live out my dreams of becoming a buff Survivor player. I take Jonathan’s upper body and algin it to a picture of me. To create my circular mask, I took my aligned selfie and create a white mask for my face. I was able to align this with the opacity features in google slides. Then, I took a screenshot and loaded this in as a array to create the irregularly shaped mask. At first, I tried using a uniform circular mask, but results weren’t to my satisfaction, so I had to fit it better.

<div class="image-row">
     
    <div class="image-container">
            <img src="images/starting_images/headshot.jpg">
    </div>
    <div class="image-container">
            <img src="images/2.4/updated_buff/aligned_headshot.png">
            
        </div>
         <div class="image-container">
            <img src="images/2.4/updated_buff/aligned_survivor.png">
            
        </div>
        <div class="image-container">
            <img src="images/starting_images/survivor.jpg">
        </div>
        <div class="image-container">
            <img src="images/2.4/updated_buff/masked.png">
    </div>
        
            
        
</div>

<div class="image-row">
    <div class="image-container">
            <img src="images/2.4/updated_buff/masked_im1_level_0.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/updated_buff/masked_im2_level_0.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/updated_buff/blended_level_0.png">
            
        </div>

</div>
<div class="image-row">
    <div class="image-container">
            <img src="images/2.4/updated_buff/masked_im1_level_2.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/updated_buff/masked_im2_level_2.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/updated_buff/blended_level_2.png">
            
        </div>

</div>
<div class="image-row">
    <div class="image-container">
            <img src="images/2.4/updated_buff/masked_im1_level_4.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/updated_buff/masked_im2_level_4.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/updated_buff/blended_level_4.png">
            
        </div>

</div>
<div class="image-row">

        <div class="image-container">
            <img src="images/2.4/avery_blended.png">
            
        </div>
        <div class="image-container">
            <img src="images/2.4/survivor_blended.png">
            
        </div>
            <div class="image-container">
            <img src="images/2.4/updated_buff/final_blended_image.png">
            
        </div>

</div>
<div class="image-row">
     
    
    <div class="image-container">
            <img src="images/2.4/updated_buff/final_blended_image.png">
            
        </div>
    
        
            
        
</div>
Besides the fact that I look really good buff, the most important thing I learned from this project was 
how challenging image editing is! Constructing the irregular mask in 2.4 took me a while and it's still not perfect.
Additionally, this makes me think about the power of generative models to alter or create imaginative images. The fact
that these models can relatively quickly and efficiently generate images is crazy as it would take a lot more time and work
to manually come up with these image modifications.


</div>
    </div>
    
